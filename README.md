# ğŸ“ Multi-Label Petition Classification Application

An end-to-end **Natural Language Processing (NLP)** application that classifies **European Union petition texts** into relevant **EUROVOC categories** using both **traditional machine learning** and **deep learning** models. The project includes a fully interactive **Streamlit web application** for real-time classification and model comparison.

---

## ğŸ” Project Overview

- **Task:** Multi-label classification of EU petitions  
- **Dataset:** EURLEX (LexGLUE benchmark) from HuggingFace  
- **Labels:** EUROVOC concept categories  
- **Models:** TF-IDF + ML models and BERT-based DL models  
- **Deployment:** Streamlit Web Application  
- **Objective:** Compare model performance and demonstrate real-time legal text classification  

Each petition can belong to **multiple EUROVOC categories**, making this a challenging and realistic multi-label NLP task.

---

## ğŸ“Š Models Implemented

| Model | Description |
|-------|-------------|
| **TF-IDF + Naive Bayes** | Probabilistic baseline classifier |
| **TF-IDF + Passive Aggressive** | Strong linear classifier for large-scale text |
| **BERT + GRU** | Contextual embeddings with sequential modeling |
| **BERT + BiLSTM** | Bidirectional sequence modeling over BERT embeddings |

---

## ğŸ“ˆ Model Performance

Performance on the EURLEX dataset:

| Model | F1 Score | Precision | Recall |
|-------|----------|-----------|--------|
| TF-IDF + Naive Bayes | 0.5566 | 0.7725 | 0.4350 |
| TF-IDF + Passive Aggressive | 0.7536 | 0.7821 | 0.7272 |
| **BERT + GRU** | **0.7585** | **0.8549** | **0.6817** |
| BERT + BiLSTM | 0.7238 | 0.8590 | 0.6254 |

**Best overall model:** **BERT + GRU**, achieving the highest F1 score with strong precision-recall balance.

---

## ğŸ–¥ï¸ Streamlit Application Features

- ğŸ”„ Model selection from sidebar  
- âœï¸ Custom petition text input  
- ğŸ“Š Confidence-based prediction display  
- ğŸ”— Clickable EUROVOC category links  
- ğŸ§ª Sample petition loader  
- ğŸŒ™ Clean, professional dark-mode UI  

---

## ğŸ“¸ Application Screenshots

<table>
  <tr>
    <td><img src="screenshots/bert_gru.png" width="400" alt="BERT + GRU"/></td>
    <td><img src="screenshots/bert_bilstm.png" width="400" alt="BERT + BiLSTM"/></td>
  </tr>
  <tr>
    <td><img src="screenshots/passive_aggressive.png" width="400" alt="Passive Aggressive"/></td>
    <td><img src="screenshots/naive_bayes.png" width="400" alt="Naive Bayes"/></td>
  </tr>
</table>

---

## ğŸ“¦ Model Files Setup

âš ï¸ **Important:** GitHub does not store large model files.

Before running the Streamlit application, ensure the following files are present in the project root directory:

```
tfidf_vectorizer.pkl
multilabel_binarizer.pkl
naive_bayes_model.pkl
passive_aggressive_model.pkl
bert_gru_model.pt
bert_bilstm_model.pt
```

### Exporting Models from Notebook

```python
import joblib
import torch

# Save TF-IDF vectorizer
joblib.dump(tfidf, "tfidf_vectorizer.pkl")

# Save MultiLabelBinarizer
joblib.dump(mlb, "multilabel_binarizer.pkl")

# Save traditional ML models
joblib.dump(model_nb, "naive_bayes_model.pkl")
joblib.dump(model_pa, "passive_aggressive_model.pkl")

# Save deep learning models
torch.save(model_bert_gru, "bert_gru_model.pt")
torch.save(model_bilstm, "bert_bilstm_model.pt")
```

---

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.8+
- pip package manager

### Installation Steps

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd NLP_FINAL_PROJECT
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Ensure model files are present** (see Model Files Setup section)

4. **Run the Streamlit application**
   ```bash
   streamlit run streamlit-app.py
   ```

5. **Open in browser**
   ```
   http://localhost:8501
   ```

---

## ğŸ“ Project Structure

```
NLP_FINAL_PROJECT/
â”œâ”€â”€ codebase.ipynb              # Main notebook with model training
â”œâ”€â”€ streamlit-app.py            # Streamlit web application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ *.pkl                       # Pickled ML models and vectorizers
â”œâ”€â”€ *.pt                        # PyTorch deep learning models
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ screenshots/                # Application screenshots
    â”œâ”€â”€ bert_gru.png
    â”œâ”€â”€ bert_bilstm.png
    â”œâ”€â”€ passive_aggressive.png
    â””â”€â”€ naive_bayes.png
```

---

## ğŸŒ EUROVOC Integration

Each predicted label links directly to the official EUROVOC concept page:

**Base URL:** `https://op.europa.eu/en/web/eu-vocabularies/eurovoc`

This allows users to explore the semantic meaning and context of each predicted category within the EU's multilingual thesaurus.

---

## ğŸ› ï¸ Technologies Used

- **Machine Learning:** scikit-learn, TF-IDF vectorization
- **Deep Learning:** PyTorch, Transformers (BERT)
- **Web Framework:** Streamlit
- **Data Processing:** pandas, numpy
- **Dataset:** HuggingFace Datasets (LexGLUE/EURLEX)

---

## ğŸ“Š Dataset Information

- **Source:** LexGLUE benchmark (Legal-domain Language Understanding Evaluation)
- **Dataset:** EURLEX (European Union legal documents)
- **Task Type:** Multi-label text classification
- **Labels:** EUROVOC thesaurus categories
- **Language:** English

---

## ğŸ¯ Future Improvements

- [ ] Add model explainability features (SHAP, LIME)
- [ ] Implement multilingual support
- [ ] Deploy to cloud platform (Streamlit Cloud, Heroku)
- [ ] Add batch prediction capability
- [ ] Incorporate user feedback loop for model improvement
- [ ] Export predictions to CSV/JSON

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¤ Author

**Umar Javeed Altaf**  
Graduate Student â€“ Artificial Intelligence  
Northeastern University

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the issues page.

---

## ğŸ“§ Contact

For questions or feedback, please reach out through:
- GitHub Issues
- Email: [your-email@northeastern.edu]

---

## â­ Acknowledgments

- HuggingFace for the EURLEX dataset
- LexGLUE benchmark creators
- EU Publications Office for EUROVOC thesaurus
- Streamlit team for the excellent framework

---

**âš–ï¸ Legal Text Classification Made Simple**
